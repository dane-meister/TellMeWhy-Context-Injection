{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4uxYPz6kOxk"
      },
      "source": [
        "# Globals for starting place in dataset, and number of api calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqQjpR-5dZHQ"
      },
      "outputs": [],
      "source": [
        "START = 67093\n",
        "NUM_API_CALLS = 750"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkVEaYE1dppj"
      },
      "source": [
        "# Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rr8m2UXMc4vZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "base_dir = '/content/drive/MyDrive/CSE_354_context_data'\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# Check if the directory exists, and create it if it doesn't\n",
        "if not os.path.exists(base_dir):\n",
        "    print(f\"Directory '{base_dir}' does not exist. Creating it...\")\n",
        "    os.makedirs(base_dir)\n",
        "else:\n",
        "    print(f\"Directory '{base_dir}' already exists.\")\n",
        "\n",
        "# Change to the directory\n",
        "%cd $base_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfcc0uObdvQT"
      },
      "source": [
        "# Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HO8iLL-zdM1J"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"StonyBrookNLP/tellmewhy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8wbvRebLdVBr"
      },
      "outputs": [],
      "source": [
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4yD2yeGdyh1"
      },
      "source": [
        "# Set up Gemini LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5n7a2AXqdnsj"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai\n",
        "import google.generativeai as genai # Import the Python SDK\n",
        "from google.colab import userdata   # Used to securely store your API key\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "Gemini = genai.GenerativeModel('gemini-pro')\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "Gemini = genai.GenerativeModel('gemini-pro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xG-wy0NJeLZi"
      },
      "outputs": [],
      "source": [
        "# Test to see if we have access\n",
        "response = Gemini.generate_content(\"Is python a scripted programming language?\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrB30SA0eZwT"
      },
      "source": [
        "# Generate context and then spit out a file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEFGZg1Keg-d"
      },
      "outputs": [],
      "source": [
        "import time # for sleeping to not overload the API\n",
        "import json # for saving data to files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52d5PVGclATW"
      },
      "outputs": [],
      "source": [
        "# gemini prompt\n",
        "prompt = '''Given the following narrative sentences that describe a story, produce a sequence of concise and to the point sentences that bring in commonsense information, and external world knowledge that is relevant. Be very verbose about commonsense knowledge and explain the reason why things are done.\n",
        "\n",
        "Here is an example:\n",
        "narrative: Cam ordered a pizza and took it home. He opened the box to take out a slice. Cam discovered that the store did not cut the pizza for him. He looked for his pizza cutter but did not find it. He had to use his chef knife to cut a slice.\n",
        "Pizza is a food. People eat food when they are hungry. Pizza is usually already cut. Cam got the pizza from the store.\n",
        "\n",
        "Produce context sentences to the following narrative without any formatting, just as a sequence of 4 short, simple, and single clause sentences, do NOT reason through multiple sentences, each sentence should state commonsense information related to the narrative:\n",
        "{narrative}\n",
        "'''\n",
        "# prompt_2 = '''You are a highly knowledgeable assistant with access to vast commonsense and world knowledge. Given the narrative story provided, generate context to enhance understanding for a smaller model. The context should include:\n",
        "\n",
        "# - Basic information about key concepts, settings, or objects mentioned in the story.\n",
        "# - Relevant external world information, such as historical, cultural, or scientific facts, that clarifies the narrative's elements.\n",
        "# - Commonsense assumptions or background details that a reader might intuitively understand but are not explicitly stated in the story.\n",
        "# Here is the narrative story: {narrative}.\n",
        "\n",
        "# Please provide the context in a concise and clear format, suitable for enriching the understanding of the story.\n",
        "# '''\n",
        "\n",
        "# lower safety settings threshold so program doesnt randomly crash\n",
        "safe = [\n",
        "    { \"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\", },\n",
        "    { \"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\", },\n",
        "    { \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\", },\n",
        "    { \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\", },\n",
        "]\n",
        "def inject_context(datum):\n",
        "  context_prompt = prompt.format(narrative=datum['narrative'])\n",
        "  context_response = Gemini.generate_content(context_prompt, safety_settings=safe)\n",
        "  datum['context'] = context_response.text\n",
        "  return datum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOCuFojbgQqD"
      },
      "outputs": [],
      "source": [
        "context_data = []\n",
        "quit_early = False\n",
        "trimmed_data_with_context = {}\n",
        "current_narrative = ''\n",
        "current_context = ''\n",
        "saved_api_calls = 0\n",
        "api_call_count = 0\n",
        "count = 0\n",
        "\n",
        "# Do NUM_API_CALLS api calls to gemini starting at START\n",
        "# Fill in context for all data with same narrative to save on api calls\n",
        "while api_call_count < NUM_API_CALLS:\n",
        "  i = START + count\n",
        "  try:\n",
        "    if current_narrative == dataset['train'][i]['narrative']: # same narrative\n",
        "      trimmed_data_with_context = {\n",
        "          'narrative': current_narrative,\n",
        "          'question': dataset['train'][i]['question'],\n",
        "          'answer': dataset['train'][i]['answer'],\n",
        "          'context': current_context,\n",
        "      }\n",
        "      saved_api_calls += 1 # we reused a context, saved an api call\n",
        "    else: # new current_narrative\n",
        "      data_with_context = inject_context(dataset['train'][i]) #calling the api\n",
        "      trimmed_data_with_context = {\n",
        "          'narrative': data_with_context['narrative'],\n",
        "          'question': data_with_context['question'],\n",
        "          'answer': data_with_context['answer'],\n",
        "          'context': data_with_context['context'],\n",
        "      }\n",
        "\n",
        "      current_narrative = data_with_context['narrative']\n",
        "      current_context = data_with_context['context']\n",
        "      api_call_count += 1\n",
        "      time.sleep(8.0) # we called the api, sleep to prevent sending too many requests\n",
        "    context_data.append(trimmed_data_with_context)\n",
        "    count += 1\n",
        "\n",
        "    percent = round(api_call_count/NUM_API_CALLS, 2)*100\n",
        "    print(f'\\rMade ({percent: 3}%) {api_call_count:4}/{NUM_API_CALLS:4} calls to the API. Number of data modified: {count}', end='')\n",
        "  except Exception as e:\n",
        "    print(f\"Error at index {i}\")\n",
        "    print(e)\n",
        "    quit_early = True\n",
        "    break\n",
        "\n",
        "filename = f'context_data_starting_at_{START}_to_{START+count}.json'\n",
        "if quit_early: #give different name if it fails, still save to maybe use\n",
        "  filename = f'failed_context_data_starting_at_{START}_to_{START + count}.json'\n",
        "\n",
        "with open(filename, 'w') as file:\n",
        "    json.dump(context_data, file, indent=2)\n",
        "\n",
        "print(f'\\n\\nSaved to file: {filename}')\n",
        "print(f'Saved {saved_api_calls} api calls, by reusing context for the same narrative')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}